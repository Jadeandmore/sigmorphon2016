<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>SIGMORPHON 2016 Shared Task: Morphological Reinflection</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">

      <h1 class="project-name">SIGMORPHON 2016 Shared Task: <br> Morphological Reinflection</h1>

      <h2 class="project-tagline"></h2>
      <a href="https://github.com/ryancotterell/sigmorphon2016" class="btn">View on GitHub</a>
      <a href="https://github.com/ryancotterell/sigmorphon2016/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/ryancotterell/sigmorphon2016/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="welcome" class="anchor" href="#welcome" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome</h2>


<p>The SIGMORPHON 2016 shared task is morphological reinflection. The
goal is to generate a new inflection given some word form.
In its most general conception the task entails both analysis of a
given form and then generation of new forms. Ideally, we would like to
generate a whole morphological paradigm (a nominal or verbal
inflection table), corresponding to a given word form. This area of computational
morphology has received a flurry of attention recently
in the NLP literature (Dreyer and Eisner (2009), Dreyer and Eisner (2011),
Durrett an DeNero (2013), Hulden et al. (2014), Nicolai, Cherry and Kondrak (2015), <em>inter alia</em>).</p>

<h2>
<a id="paradigm-completion--a-brief-introduction" class="anchor" href="#paradigm-completion--a-brief-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Morphological Inflection – A Brief Introduction</h2>

<p>In many of the world's languages words change their form to express different syntactic
and semantic relationships in a structured fashion. For instance, English generally overtly marks the plural with a final 
"s", as in "model" → "models". Even for novel words, native speakers are perfectly capable 
of generating the correct inflections (consider "wug" → "wugs"), making these processes
highly productive. The act of modifying word forms to express these relationships is termed <em>inflection</em> (often <em>conjugation</em> when referring to verbs and <em>declension</em> when referring to nouns).
In English, this task is relatively uninteresting, e.g., English
substantives only distinguish singular and plural. 
But many of the world's languages
exhibit a high degree of inflection making this a hard computational problem.
In Polish, for example, a single verb can have over a 100 forms! This sort of linguistic
productivity creates data sparsity problems for most other NLP tasks. With this shared task, we hope to
make a progress in the community's ability to automate this aspect of computational morphology.</p>


<h2>
<a id="shared-task-philosophy" class="anchor" href="#shared-task-philosophy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Shared Task Philosophy</h2>

<p>A primary motivation behind this shared task is to spread
interest in computational morphology. In comparison 
to computational efforts in syntax and semantics, morphology
receives far less attention. This is in part because
researchers often work on English, a inflectionally impoverished
language, but also because there are fewer standardized resources. 
With this in mind, we designed our first shared task to be
both useful, but also <em>easily accessible</em> to researchers
and students who have previously considered the area. Additionally,
all resources required for this shared task will be open source, that is
available to everyone for free. </p>

<h3>
<a id="task-1--reranking-reinflection" class="anchor" href="#task-1--reranking-reinflection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Task 1 – Reranking Reinflection</h3>
<p><font size="4" color="red">DECISION POINT: In the meeting we discussed an "entry level" task to ensure that anyone who wanted could easily participate.
Does this task work for everyone? It was the simplest thing that popped into my mind, but we don't have to stick with it.</font></p>


<p>The first task we consider is reranking of reinflection.
The goal is to be able to learn function that reinflects
a word form to another word form in the same paradigm. For instance,
in English the system may be given "eating" and told to generate the past participle,
which is "eaten". The goal of this task is to be relatively easy and
have a lower barrier to entry. We will provide
each system with a set of word forms, their structured morphological
tag, i.e, as described in Sylak-Glassman et al. (2015), and the structured
morphological tag of the <em>target word form</em>. Additionally, each system
is given a set of candidates to chose among allowing this task to
perform with simpler classifiers. </p>

<ul>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task1/train">Train</a></li>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task1/dev">Dev</a></li>
<li>Test</li>
</ul>

<h3>
<a id="task-2--full-paradigm-generation" class="anchor" href="#task-2--full-paradigm-generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Task 2 – Full Paradigm Generation</h3>


<p><font size="4" color="red">DECISION POINT: All of these tasks focus on generating the whole paradigm. We will evaluate both on forms and whole tables. Do we also want to generate individual inflections without the whole paradigm?</font></p>

<p><font size="4" color="red">DECISION POINT: We discussed different granularities for the reinflection task. Are these three distinctions enough? Too much? Do they capture all the nuances of the task we want?</font></p>

<p>The second task is full-blown paradigm completion. The goal
here is to generate the <em>full paradigm</em> from a given 
word form in the paradigm in various settings. We have
ordered the settings in order of their difficult and we expect
systems to be able compete in all three tracks.</p>

<h4>
<a id="setting-1--lemma-to-full-paradigm" class="anchor" href="#setting-1--lemma-to-full-paradigm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting 1 – Lemma to Full Paradigm</h4>

<p>The first setting we consider is generating
a full paradigm from a lemma. This is
the task introduced in Durrett and DeNero (2013). 
This setting is by far the easiest and a variety
of researched, e.g., Hulden et al. (2014), and Nicolai, Cherry and Kondrak (2015),
have achieved developed high-performance systems. </p>

<ul>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting1/train">Train</a></li>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting1/dev">Dev</a></li>
<li>Test</li>
</ul>

<h4>
<a id="setting-2--slot-to-full-paradigm" class="anchor" href="#setting-2--slot-to-full-paradigm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting 2 – Slot to Full Paradigm</h4>

<p>The second task is generating the full paradigm
from an arbitrary word form in the paradigm. This is very similar
to the task introduced in Dreyer and Eisner (2009), 
with the exception that we will never give a system
more than one word form from which to generalize.
To be more concrete, the training data will consist of
pairs of word forms labeled with their structured tag
and corresponding complete paradigm. The word form will be a slot sampled
uniformly at random from the paradigm.</p>

<ul>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting2/train">Train</a></li>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting2/dev">Dev</a></li>
<li>Test</li>
</ul>

<h4>
<a id="setting-3--slot-to-full-paradigm" class="anchor" href="#setting-3--slot-to-full-paradigm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting 3 – Slot to Full Paradigm++</h4>

<p>The third track is a variation of Track 2 with two small twists: we will
(i) not provide the structured tag with the word form in the training or 
test data and (ii) the training data will have incomplete paradigms, i.e., only
a subset of the slots will be given to train on. Both of these conditions
represent noise that one should expect to find in the "wild", where data is often
unlabeled and missing. In short, we would like to make computational morphological systems
robust. </p>

<ul>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting3/train">Train</a></li>
<li><a href="https://github.com/ryancotterell/sigmorphon2016/tree/master/data/task2/setting3/dev">Dev</a></li>
<li>Test</li>
</ul>

<h2>
<a id="the-languages" class="anchor" href="#the-languages" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Languages</h2>


<p><font size="4" color="red">DECISION POINT: Is everyone ok with these languages? I tried to balance languages that have been studied
with new ones, but at the same time I tried not to overwhelm the participants with too many. Johns Hopkins will provide all data 
(from Wiktionary) and it will be open source.</font></p>

<p><font size="4" color="red">DECISION POINT: I think we should stick to orthographic forms (not phonological, i.e., IPA) for this first
task. Does everyone agree there?.</font></p>


<p>In our selection of languages, we have sought a representative
sample of the world's languages (albeit biased to those with rich inflection).
We chose the following 8 languages: Spanish, German, Finnish, Russian, Turkish, Greenlandic, Navajo and Armenian.
All of the data has been scraped from Wiktionary and undergone additional
processing at the <a href="http://www.clsp.jhu.edu/">Center for Language and Speech Processing</a> at <a href="https://www.jhu.edu/">Johns Hopkins University</a>. The data are formatted according to the schema described in Sylak-Glassman et al. (2015).</p>

<ul>
<li><p><strong>Spanish</strong>: Spanish is a Romance language, branch of the larger Indo-European family, that originated in the Castile region of Spain. More than 400 million people speak Spanish as a native language, making it second only to Mandarin in terms of its number of native speakers worldwide. </p></li>
<li><p><strong>German:</strong> German is a West Germanic language that derives most of its vocabulary from the Germanic branch of the Indo-European language family. It is spoken by 90 million people in central Europe.</p></li>
<li><p><strong>Finnish:</strong> Finnish is the language spoken by the majority of the population in Finland and by ethnic Finns outside Finland. It has 5.4 million speakers.</p></li>
<li><p><strong>Russian:</strong> Russian is an East Slavic language and an official language in Russia, Belarus, Kazakhstan, and Kyrgyzstan. It is an unofficial but widely spoken language in Ukraine, Moldova, Latvia and Estonia. Russian belongs to the family of Indo-European languages and is one of the three living members of the East Slavic languages. It has 150 million native speakers and 260 speakers total.</p></li>
<li><p><strong>Turkish:</strong> Turkish is the most widely spoken of the Turkic languages, with around 63 million native speakers. Speakers are located predominantly in Turkey, with smaller groups in Germany, Bulgaria, Macedonia, Northern Cyprus, Greece, the Caucasus, and other parts of Europe and Central Asia.</p></li>
<li><p><strong>Greenlandic:</strong> Greenlandic is an Eskimo–Aleut language spoken by about 57,000 Greenlandic Inuit people in Greenland. It is closely related to the Inuit languages in Canada, such as Inuktitut. The main dialect, Kalaallisut or West Greenlandic, has been the official language of the Greenlandic autonomous territory since June 2009.</p></li>
<li><p><strong>Navajo:</strong> Navajo is a language of the Athabaskan branch of the Na-Dené family, by which it is related to languages spoken across the western areas of North America. Navajo is spoken primarily in the Southwestern United States, especially in the Navajo Nation political area. It is one of the most widely spoken Native American languages with almost 170,000 Americans speaking Navajo at home as of 2011.</p></li>
<li><p><strong>Armenian:</strong> The Armenian language is an Indo-European language spoken by the Armenians. It is the official language of the Republic of Armenia and the self-proclaimed Nagorno-Karabakh Republic. It has historically been spoken throughout the Armenian Highlands and today is widely spoken in the Armenian diaspora. In total the language has 6 million speakers.</p></li>
<li><p><strong>Surprise Language 1:</strong> 
The second surprise language! All data (train, dev and test) will be distributed 72 hours before
the evaluation.</p></li>
<li><p><strong>Surprise Language 2:</strong> The second surprise language! All data (train, dev and test) will be distributed 72 hours before
the evaluation.</p></li>

</ul>


<h2>
<a id="external_resources" class="anchor" href="#external_resources" aria-hidden="true"><span class="octicon octicon-link"></span></a>External Resources</h2>

<p><font size="4" color="red">DECISION POINT: What other external resources should be allowed?</font></p>
<p><font size="4" color="red">DECISION POINT: I think we should evaluate two tracks: one without external resources and one with all those allowed. Do we want a third open track where anything goes?</font></p>

<p>In order to ensure a level playing field, we insist that only
external resources listed below be used in the competing
systems. We may further ask for ablation studies regarding
these resources. </p>

<ul>
<li><strong>Monolingual Corpora:</strong> We will provide monolingual corpora for all languages. These will be Wikipedia backup
dumps. We insist that no other monolingual resources be used and that all systems report numbers both <em>with</em> and <em>without</em> the resources.</li>
</ul>





<h2>
<a id="evaluation" class="anchor" href="#evaluation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation</h2>
<p><font size="4" color="red">DECISION POINT: We probably need to formulate a clear plan for conducting the evaluation. My current idea is to release the data 72 hours before the deadline and have each group self-report numbers.  </font></p>

<p><font size="4" color="red">DECISION POINT: I think the evaluation metric, accuracy, is set. Unless someone has a different suggestion? The main question here is how to sample the train, dev, test splits. Options include sampling the split with a uniform distribution over types or a distribution determined by token frequency. The later would put more irregulars in the train and dev splits and rarer forms in test split. Comments? </font></p>



<p>We will provide the test sets for evaluation 72 hours before the deadline along with the train and dev sets for
the surprise languages. Systems will be evaluated on both per form accuracy and per table accuracy. </p>


<h2>
<a id="bibliography" class="anchor" href="#bibliography" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bibliography</h2>

<ul>
<li>Greg Durrett, John DeNero. Supervised Learning of Complete Morphological Paradigms. NAACL. 2013.</li>
<li>Markus Dreyer, Jason Eisner. Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model. EMNLP. 2011.</li>
<li>Markus Dreyer, Jason Eisner. Graphical Models over Multiple Strings. EMNLP. 2009.</li>
<li>Nicolai, Garrett  and  Cherry, Colin  and  Kondrak, Grzegorz. Inflection Generation as Discriminative String Transduction. NAACL 2015. </li>
<li>Mans Hulden, Markus Forsberg, Malin Ahlberg. Semi-supervised learning of morphological paradigms and lexicons. EACL. 2014.</li>
<li>Mans Hulden. Generalizing inflection tables into paradigms with finite state operations. SIGMORPHON. 2014. </li>
<li>Ahlberg, Malin  and  Forsberg, Markus  and  Hulden, Mans. Paradigm classification in supervised learning of morphology. NAACL. 2015. </li>
<li>Sylak-Glassman, John, Kirov, Christo,  Yarowsky, David and Que, Roger. A Language-Independent Feature Schema for Inflectional Morphology. ACL. 2015.</li>
</ul>

<p>Please direct all correspondence regarding the shared task to <a href="mailto:ryan.cotterell@gmail.com">ryan.cotterell@gmail.com</a>.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/ryancotterell/sigmorphon2016">SIGMORPHON 2016 Shared Task: &lt;br&gt; Morphological Reinflection</a> is maintained by <a href="https://github.com/ryancotterell">ryancotterell</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

